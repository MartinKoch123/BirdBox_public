{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"..\")\n",
    "import torch\n",
    "from pysot.core.config import cfg\n",
    "from pysot.models.model_builder import ModelBuilder\n",
    "from pysot.tracker.tracker_builder import build_tracker\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import PIL.Image as PIL_Image\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from IPython.display import clear_output, display\n",
    "from birdbox.tools import process_video, Rect, crop_to_square_crop, cv2_putText, video_drop_down\n",
    "from birdbox.detection import detect_birds, load_detector, Detection\n",
    "from birdbox.classifiers import Classifier\n",
    "from object_detection.utils import visualization_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# DETECTOR_MODEL_NAME = \"centernet_hg104_1024x1024_coco17_tpu-32\"\n",
    "DETECTOR_MODEL_NAME = \"ssd_mobilenet_v2_320x320_coco17_tpu-8\"\n",
    "\n",
    "CLASSIFIER_NAME = \"EfficientNetB0_120x120_1-3-4-5-6-7-8-9-10-11-12\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier = Classifier.load(CLASSIFIER_NAME)\n",
    "class_names = {value[\"id\"]: value[\"name\"] for key, value in classifier.category_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done! Took 8.08270812034607s\n"
     ]
    }
   ],
   "source": [
    "[detect_fn, category_index] = load_detector(model_name=DETECTOR_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def draw_box_with_title(frame, box, title=None):\n",
    "\n",
    "    visualization_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        frame,\n",
    "        np.array([(box.top, box.left, box.bottom, box.right)]),\n",
    "        [1],\n",
    "        [1],\n",
    "        {1: {\"id\": 1, \"name\": title}},\n",
    "        skip_scores=True\n",
    "    )\n",
    "\n",
    "\n",
    "class DetectionAndTrackingProcessor:\n",
    "    CONFIG_FILE = Path(r\"..\\models\\pysot\\siamrpn_r50_l234_dwxcorr\\config.yaml\")\n",
    "    SNAPSHOT_FILE = Path(r\"..\\models\\pysot\\siamrpn_r50_l234_dwxcorr\\model.pth\")\n",
    "    MIN_SCORE = 0.5\n",
    "    HISTORY_LENGTH = 100\n",
    "\n",
    "    def __init__(self):\n",
    "        self.init_box = None\n",
    "        cfg.merge_from_file(self.CONFIG_FILE)\n",
    "        cfg.CUDA = torch.cuda.is_available() and cfg.CUDA\n",
    "        device = torch.device('cuda' if cfg.CUDA else 'cpu')\n",
    "        model = ModelBuilder()\n",
    "        model.load_state_dict(torch.load(self.SNAPSHOT_FILE, map_location=lambda storage, loc: storage.cpu()))\n",
    "        model.eval().to(device)\n",
    "        self.tracker = build_tracker(model)\n",
    "        self.class_history = []\n",
    "\n",
    "    def __call__(self, frame):\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image_pil = PIL_Image.fromarray(frame_rgb)\n",
    "\n",
    "        # Initialize tracking target\n",
    "        if not self.init_box:\n",
    "\n",
    "            detections = detect_birds(frame_rgb, detect_fn, min_score=0.1, max_intersection_over_size=0)\n",
    "            if len(detections) == 0:\n",
    "                return\n",
    "\n",
    "            self.init_box = detections[0].box * image_pil.size\n",
    "            self.tracker.init(frame, self.init_box.left_top_width_height())\n",
    "            return\n",
    "\n",
    "        # Track\n",
    "        outputs = self.tracker.track(frame)\n",
    "        tracking_score = outputs[\"best_score\"]\n",
    "\n",
    "        # Abort for small tracking score\n",
    "        if tracking_score < self.MIN_SCORE:\n",
    "            self.init_box = None\n",
    "            self.class_history = []\n",
    "            return\n",
    "        # print(tracking_score)\n",
    "\n",
    "        # Build classification crop\n",
    "        box = round(Rect.from_left_top_width_height(*outputs['bbox']))\n",
    "        classifier_box = crop_to_square_crop(box, image_pil.size)\n",
    "        bird_crop = image_pil.crop(classifier_box)\n",
    "\n",
    "        # Classify\n",
    "        if tracking_score < 0.9999 or len(self.class_history) == 0:\n",
    "            image_tf = tf.expand_dims(np.array(bird_crop.resize(classifier.image_size)), 0)\n",
    "            prediction = classifier.model.predict(image_tf)\n",
    "            current_class = class_names[prediction[0].argmax() + 1]\n",
    "            if len(self.class_history) == self.HISTORY_LENGTH:\n",
    "                self.class_history.pop(0)\n",
    "            self.class_history.append(current_class)\n",
    "\n",
    "        # Determine best guess\n",
    "        classification_counts = dict()\n",
    "        for name in class_names.values():\n",
    "            count = self.class_history.count(name)\n",
    "            classification_counts[name] = count\n",
    "\n",
    "        best_guess = max(classification_counts, key=lambda key: classification_counts[key])\n",
    "        best_count = classification_counts[best_guess]\n",
    "\n",
    "#         draw_box_with_title(frame, box, title=f\"{tracking_score * 100:.0f} {best_guess} {best_count / self.HISTORY_LENGTH * 100:.0f}%\")\n",
    "        draw_box_with_title(frame, box, title=f\"{best_guess} {best_count / self.HISTORY_LENGTH * 100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e79efab11b49e58a40cee1f9cea2d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Video file:', options=('Blue_tit_vs_chaffinch.mp4', 'Verl_red_robin_in_water.mp4', 'Grouâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drop_down = video_drop_down()\n",
    "display(drop_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# video = Path(r\"..\\videos\") / drop_down.value\n",
    "# video = Path(r\"..\\videos\\wald\\great_tit_drinking.mp4\")\n",
    "# video = Path(r\"..\\videos\\wald\\sparrows.mp4\")\n",
    "video = Path(r\"..\\videos\\wald\\robin.mp4\")\n",
    "# skips = {\"Ground_feeding\": 0, \"Blue_tit_vs_chaffinch\": 1, \"Verl_red_robin_in_water\": 0, \"Ground_feeding2\": 0, \"great_tit_drinking\": 1}\n",
    "# skip = skips[video.stem]\n",
    "skip = 0\n",
    "# output_path = None\n",
    "output_path = Path(r\"..\\videos\\results\") / (video.stem + \".avi\")\n",
    "process_video(video, DetectionAndTrackingProcessor(), skip=skip, start=150, output_path=output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
